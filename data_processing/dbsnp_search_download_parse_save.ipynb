{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "home_dir = \"../\"\n",
    "\n",
    "import time\n",
    "import os\n",
    "from Bio import Entrez\n",
    "from urllib.error import HTTPError\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import xmltodict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This runs a query in the dbsnp database, downloads the data in batches, and parses the xml format dbsnp query results, and saves in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query result count:: 5141322, Fetch count: 10283\n"
     ]
    }
   ],
   "source": [
    "Entrez.email = \"akabir0101@gmail.com\" # provide your user email \n",
    "# RECOMMENDED: apply for API key from NCBI (https://ncbiinsights.ncbi.nlm.nih.gov/2017/11/02/new-api-keys-for-the-e-utilities/). \n",
    "# 10 queries per second with a valid API key, otherwise 3 queries per seconds are allowed for 'None'\n",
    "Entrez.api_key = \"328570309ccd040632796143ec88b51bcf08\"\n",
    "retmax = 500 # return 20 rs per batch example, max=1000\n",
    "namespace = \"https://www.ncbi.nlm.nih.gov/SNP/docsum\"\n",
    "ns = u'{%s}' % namespace\n",
    "nsl = len(ns)\n",
    "\n",
    "# dbSNP supported query terms (https://www.ncbi.nlm.nih.gov/snp/docs/entrez_help/) can be build and test online using web query builder (https://www.ncbi.nlm.nih.gov/snp/advanced) \n",
    "# esearch handle\n",
    "eShandle = Entrez.esearch(db=\"snp\",  # search dbSNP\n",
    "                          term='\"humo sapiens\"[Organism] AND \"missense variant\"[Function Class] AND \"snp protein\"[Filter] AND \"validated by alfa\"[Filter]',\n",
    "                          usehistory=\"y\", #cache result on server for download in batches\n",
    "                          retmax=retmax\n",
    "                         )                        \n",
    "\n",
    "# get esearch result\n",
    "eSresult = Entrez.read(eShandle)\n",
    "webenv = eSresult[\"WebEnv\"]\n",
    "query_key = eSresult[\"QueryKey\"]\n",
    "total_count = int(eSresult[\"Count\"])\n",
    "print(f\"Query result count:: {total_count}, Fetch count: {len(range(0, total_count, retmax))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response_xml(x:str):\n",
    "    o = xmltodict.parse(x) #returns dict obj\n",
    "    docs = o[\"ExchangeSet\"][\"DocumentSummary\"]\n",
    "\n",
    "    outs = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        genes = doc[\"GENES\"][\"GENE_E\"] # can have multiples\n",
    "        if isinstance(genes, list):\n",
    "            genes = [f'{gene[\"NAME\"]}:{gene[\"GENE_ID\"]}' for gene in genes]\n",
    "            genes = \",\".join(genes)\n",
    "        elif isinstance(genes, dict):\n",
    "            genes = f'{genes[\"NAME\"]}:{genes[\"GENE_ID\"]}'\n",
    "        # print(genes)\n",
    "\n",
    "        \n",
    "        mafs = doc[\"GLOBAL_MAFS\"][\"MAF\"] # can have multiples\n",
    "        # print(doc)\n",
    "        if isinstance(mafs, list):\n",
    "            mafs = [f'{maf[\"STUDY\"]}:{maf[\"FREQ\"]}' for maf in mafs]\n",
    "            mafs = \",\".join(mafs)\n",
    "        elif isinstance(mafs, dict):\n",
    "            mafs = f'{mafs[\"STUDY\"]}:{mafs[\"FREQ\"]}'\n",
    "            \n",
    "\n",
    "        variations = doc[\"DOCSUM\"] # an example: HGVS=NC_000023.11:g.154360389T>A,NC_000023.11:g.154360389T>C,NW_003871103.3:g.1794368T>A,NW_003871103.3:g.1794368T>C,NG_011506.2:g.19250A>T,NG_011506.2:g.19250A>G,NM_001456.4:c.3406A>T,NM_001456.4:c.3406A>G,NM_001456.3:c.3406A>T,NM_001456.3:c.3406A>G,NM_001110556.2:c.3406A>T,NM_001110556.2:c.3406A>G,NM_001110556.1:c.3406A>T,NM_001110556.1:c.3406A>G,NC_000023.10:g.153588757T>A,NC_000023.10:g.153588757T>C,NP_001447.2:p.Ile1136Phe,NP_001447.2:p.Ile1136Val,NP_001104026.1:p.Ile1136Phe,NP_001104026.1:p.Ile1136Val|SEQ=[T/A/C]|LEN=1|GENE=FLNA:2316\n",
    "        variations = (variations[5:].split(\"|\")[0]).split(\",\")\n",
    "        variations = [v for v in variations if v.startswith(\"NP_\")]\n",
    "        variations = \",\".join(variations)\n",
    "        \n",
    "        data = {\n",
    "            \"snp_id\": doc[\"SNP_ID\"],\n",
    "            \"acc\": doc[\"ACC\"],\n",
    "            \"chrpos\": doc[\"CHRPOS\"],\n",
    "            \"spdi\": doc[\"SPDI\"],\n",
    "            \"tax_id\": doc[\"TAX_ID\"],\n",
    "            \"snp_class\": doc[\"SNP_CLASS\"],\n",
    "            \"create_date\": doc[\"CREATEDATE\"],\n",
    "            \"update_date\": doc[\"UPDATEDATE\"],\n",
    "            \"clinical_significance\": doc[\"CLINICAL_SIGNIFICANCE\"],\n",
    "            \"fxn_class\": doc[\"FXN_CLASS\"],\n",
    "            \"validated\": doc[\"VALIDATED\"],\n",
    "            \"genes\": genes,\n",
    "            \"mafs\": mafs,\n",
    "            \"variations\": variations\n",
    "        }\n",
    "        outs.append(data)\n",
    "        \n",
    "        # if i==1: break\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(data, out_filepath:str):\n",
    "    # data: list of objects\n",
    "    out_df = pd.DataFrame(data)\n",
    "    if not os.path.exists(out_filepath):\n",
    "        out_df.to_csv(out_filepath, chunksize=10000, sep=\"\\t\", index=False, mode=\"a\", header=True)\n",
    "    else:\n",
    "        out_df.to_csv(out_filepath, chunksize=10000, sep=\"\\t\", index=False, mode=\"a\", header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_batch(start, retmax):\n",
    "    attempt = 0\n",
    "    while (attempt < 3):\n",
    "        attempt += 1\n",
    "        try:\n",
    "            fetch_handle = Entrez.efetch(db=\"snp\",\n",
    "                                        # rettype=\"\",\n",
    "                                        retmode=\"xml\",\n",
    "                                        retstart=start,\n",
    "                                        retmax=retmax,\n",
    "                                        webenv=webenv,\n",
    "                                        query_key=query_key)\n",
    "            break\n",
    "        except HTTPError as err:\n",
    "            if 400 <= err.code <= 599:\n",
    "                print(\"Received error from server %s\" % err)\n",
    "                print(\"Attempt %i of 3\" % attempt)\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                raise\n",
    "    try:                \n",
    "        data = fetch_handle.read().decode()\n",
    "        data = parse_response_xml(data)\n",
    "        fetch_handle.close()\n",
    "        return data\n",
    "    except:\n",
    "        print(f\"Error. Downloading again record {start+1} to {start+retmax}\")\n",
    "        return download_batch(start, retmax)\n",
    "    # return fetch_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch no: 1\tDownloading record 1 to 500\n"
     ]
    }
   ],
   "source": [
    "# sample codes adopted with modifications from http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc139.\n",
    "out_filepath = home_dir+\"data/dbsnp/search_results/dbsnp_HumanMissenseALFAVariants_x.txt\"\n",
    "# if os.path.exists(out_filepath): os.remove(out_filepath)\n",
    "\n",
    "\n",
    "fetch_count = 1 # 1-indexed\n",
    "start_idx = 0 # 0-indexed\n",
    "for start in range(start_idx, total_count, retmax):\n",
    "    end = min(total_count, start+retmax)\n",
    "    print(f\"Fetch no: {fetch_count}\\tDownloading record {start+1} to {end}\")\n",
    "    data = download_batch(start, retmax)\n",
    "    save(data, out_filepath)\n",
    "        \n",
    "    if fetch_count==1: break\n",
    "    fetch_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hopper_variant_effect_analysis_mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "831918974231b2fc7cbf226cf19505a68e47ade0e201ebff2df92e599b5c76db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
