{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "home_dir = \"../../\"\n",
    "module_path = os.path.abspath(os.path.join(home_dir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ashehu/akabir4/venvs/hopper_tape_rao/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ProteinBertForMaskedLM(\n",
       "  (bert): ProteinBertModel(\n",
       "    (embeddings): ProteinBertEmbeddings(\n",
       "      (word_embeddings): Embedding(30, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(8192, 768)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ProteinBertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ProteinBertLayer(\n",
       "          (attention): ProteinBertAttention(\n",
       "            (self): ProteinBertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ProteinBertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ProteinBertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ProteinBertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): ProteinBertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (mlm): MLMHead(\n",
       "    (transform): PredictionHeadTransform(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (LayerNorm): LayerNorm()\n",
       "    )\n",
       "    (decoder): Linear(in_features=768, out_features=30, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tape import ProteinBertModel, TAPETokenizer, ProteinBertForMaskedLM\n",
    "# model = ProteinBertModel.from_pretrained('bert-base', force_download=True)\n",
    "model = ProteinBertForMaskedLM.from_pretrained('bert-base')#, force_download=True)\n",
    "tokenizer = TAPETokenizer(vocab='iupac')  # iupac is the vocab for TAPE models, use unirep for the UniRep model\n",
    "model = model.to(\"cpu\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0079, -0.0353, -0.0143,  ...,  0.0406, -0.0008,  0.0108],\n",
       "        [ 0.0398, -0.0075, -0.0351,  ...,  0.0365,  0.0097,  0.0137],\n",
       "        [-0.0168, -0.0186, -0.0212,  ..., -0.0174,  0.0334, -0.0053],\n",
       "        ...,\n",
       "        [-0.0386, -0.0032, -0.0156,  ...,  0.0421, -0.0131,  0.0138],\n",
       "        [-0.0392, -0.0253, -0.0334,  ..., -0.0235,  0.0122, -0.0710],\n",
       "        [ 0.0128, -0.0218, -0.0280,  ...,  0.0126, -0.0004,  0.0260]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.mlm.decoder.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('<pad>', 0),\n",
       "             ('<mask>', 1),\n",
       "             ('<cls>', 2),\n",
       "             ('<sep>', 3),\n",
       "             ('<unk>', 4),\n",
       "             ('A', 5),\n",
       "             ('B', 6),\n",
       "             ('C', 7),\n",
       "             ('D', 8),\n",
       "             ('E', 9),\n",
       "             ('F', 10),\n",
       "             ('G', 11),\n",
       "             ('H', 12),\n",
       "             ('I', 13),\n",
       "             ('K', 14),\n",
       "             ('L', 15),\n",
       "             ('M', 16),\n",
       "             ('N', 17),\n",
       "             ('O', 18),\n",
       "             ('P', 19),\n",
       "             ('Q', 20),\n",
       "             ('R', 21),\n",
       "             ('S', 22),\n",
       "             ('T', 23),\n",
       "             ('U', 24),\n",
       "             ('V', 25),\n",
       "             ('W', 26),\n",
       "             ('X', 27),\n",
       "             ('Y', 28),\n",
       "             ('Z', 29)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.572329   -11.0084915  -12.411443    -9.077562   -14.077164\n",
      "   1.4255943  -12.878991     0.9913696    1.451469     1.3550032\n",
      "   2.0718853    1.5725293    1.2201787    2.0912328    1.5908126\n",
      "   2.3223362    0.8785827    1.8224728  -12.962563     1.5508606\n",
      "   1.4145026    1.4866153    5.767225     1.8694699   -9.500174\n",
      "   1.806958     0.81860864  -5.78228      1.7986705  -12.370768  ]\n",
      "[-14.41481    -10.875704   -12.323403    -8.911601   -13.955445\n",
      "   1.4228826  -12.721293     1.0631462    1.420688     1.2446738\n",
      "   2.1930194    1.5513582    1.2077374    2.156792     1.5138537\n",
      "   2.4022515    0.9481643    1.7951783  -12.835764     1.4154377\n",
      "   1.3266288    1.465413     5.7771254    1.8574655   -9.422638\n",
      "   1.8540447    0.81553805  -5.622466     1.8164994  -12.252094  ]\n"
     ]
    }
   ],
   "source": [
    "import utils.pickle_utils as pickle_utils\n",
    "logits_1 = pickle_utils.load_pickle(home_dir+f\"models/tape_rao/outputs/protbert/lm_outputs/A000006_2_271.pkl\") \n",
    "logits_2 = pickle_utils.load_pickle(home_dir+f\"models/tape_rao/outputs/protbert/lm_outputs/A000006_2_62.pkl\") \n",
    "\n",
    "# now see, logits in masked position are different, \n",
    "print(logits_1[270])\n",
    "print(logits_2[270])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', '<mask>', 'A']\n",
      "tensor([[ 2, 11,  1,  5,  3]])\n",
      "(5, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.9393923 ,   1.4764738 ,  17.069212  ,   4.093584  ,\n",
       "          2.2064114 ,   3.540858  ,   1.4473366 ,   2.1282196 ,\n",
       "          1.6636357 ,   3.559037  ,   0.75567114,   1.4647713 ,\n",
       "          3.0634506 ,  -0.91880214,  -1.1657937 ,   3.1354527 ,\n",
       "          3.758852  ,   4.13353   ,   2.2984781 ,  -1.1430006 ,\n",
       "          1.0028296 ,  -0.73765385,   1.8968856 ,   2.0362754 ,\n",
       "          1.1207702 ,   1.3910527 ,  -0.8755777 ,   0.6121899 ,\n",
       "          1.4712923 ,   1.8130984 ],\n",
       "       [ -9.174221  ,  -7.324638  ,  -7.451663  ,  -2.8247697 ,\n",
       "         -8.93935   ,   2.8364978 ,  -8.080409  ,  -2.5297391 ,\n",
       "          4.2169266 ,   2.5058782 ,  -0.0582124 ,   8.556776  ,\n",
       "          1.5619744 ,  -0.62475365,   3.1155698 ,   0.312629  ,\n",
       "          0.7278353 ,   3.1459618 ,  -8.427874  ,   3.038825  ,\n",
       "          2.153031  ,   3.0776536 ,   2.90188   ,   2.3127396 ,\n",
       "         -6.1784453 ,   0.7753676 ,  -2.248705  ,  -1.1377429 ,\n",
       "         -0.21283606,  -8.4147415 ],\n",
       "       [-13.875187  ,  -9.965241  , -10.7789955 ,  -6.9071617 ,\n",
       "        -11.862724  ,   3.2019403 , -11.741604  ,  -0.22070232,\n",
       "          0.8484168 ,   1.4928479 ,   5.039672  ,   2.5502315 ,\n",
       "          1.6921804 ,   0.36403123,   3.8289897 ,   1.6629293 ,\n",
       "          0.82346904,   1.4806576 , -11.731367  ,   2.0673966 ,\n",
       "          2.0040605 ,   5.0040836 ,   2.6360343 ,   2.153886  ,\n",
       "         -8.728531  ,   1.7212989 ,   0.496418  ,  -3.6878808 ,\n",
       "          2.6595047 , -11.48115   ],\n",
       "       [ -9.455706  ,  -6.1300716 ,  -7.5951157 ,  -2.1290858 ,\n",
       "         -7.8473244 ,   5.386862  ,  -7.198853  ,  -1.703078  ,\n",
       "          3.236093  ,   1.9212298 ,   0.6322969 ,   6.269956  ,\n",
       "          3.6810513 ,  -0.533725  ,   3.1090515 ,  -0.17099248,\n",
       "         -0.55616504,   1.7927942 ,  -7.1924    ,   2.4700947 ,\n",
       "          2.0946455 ,   3.4980965 ,   2.2329876 ,   1.392871  ,\n",
       "         -5.5714912 ,   0.25470468,  -1.2355419 ,  -4.97182   ,\n",
       "          0.0192603 ,  -6.994363  ],\n",
       "       [-14.503357  , -10.747157  , -11.422384  ,  -7.0733156 ,\n",
       "        -12.861308  ,   3.448507  , -12.074245  ,  -0.6993166 ,\n",
       "          0.7601086 ,   1.115058  ,   2.8476562 ,   3.560817  ,\n",
       "          1.4341042 ,   1.972462  ,   2.564108  ,   2.5913935 ,\n",
       "          2.1745212 ,   1.4192226 , -12.119053  ,   4.2315097 ,\n",
       "          2.4996638 ,   3.598045  ,   2.9192743 ,   3.1607296 ,\n",
       "         -9.242243  ,   2.896141  ,  -0.5256584 ,  -3.800346  ,\n",
       "          1.5444705 , -12.1198435 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "seq = list('GCA')\n",
    "mut_pos_zero_idxd = 1\n",
    "seq[mut_pos_zero_idxd] = \"<mask>\"\n",
    "print(seq)\n",
    "token_ids = torch.tensor(np.array([tokenizer.encode(seq)]))\n",
    "print(token_ids)\n",
    "with torch.no_grad():\n",
    "    output = model(token_ids)[0][0].detach().numpy()\n",
    "print(output.shape)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ashehu/akabir4/venvs/hopper_tape_rao/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 72879855/72879855 [00:01<00:00, 42691361.66B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UniRepForLM(\n",
       "  (unirep): UniRepModel(\n",
       "    (embed_matrix): Embedding(26, 10)\n",
       "    (encoder): mLSTM(\n",
       "      (mlstm_cell): mLSTMCell(\n",
       "        (wmx): Linear(in_features=10, out_features=1900, bias=False)\n",
       "        (wmh): Linear(in_features=1900, out_features=1900, bias=False)\n",
       "        (wx): Linear(in_features=10, out_features=7600, bias=False)\n",
       "        (wh): Linear(in_features=1900, out_features=7600, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feedforward): Linear(in_features=1900, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tape import UniRepForLM, TAPETokenizer, UniRepModel\n",
    "tokenizer = TAPETokenizer(vocab='unirep')\n",
    "\n",
    "cache_dir=home_dir+\"models/tape_rao/cache/unirep\"\n",
    "model = UniRepForLM.from_pretrained('babbler-1900', cache_dir=cache_dir) # force_download=True\n",
    "# model = UniRepModel.from_pretrained('babbler-1900', force_download=True, cache_dir=cache_dir)\n",
    "model = model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0335,  0.0224, -0.0772,  ...,  0.0020,  0.0077, -0.0977],\n",
      "        [ 0.1135,  0.0177, -0.1351,  ..., -0.0046, -0.0181, -0.0206],\n",
      "        [-0.1942, -0.0078, -0.1548,  ..., -0.0168, -0.0323, -0.0569],\n",
      "        ...,\n",
      "        [-0.1097,  0.0126,  0.0210,  ...,  0.0075,  0.0143,  0.0834],\n",
      "        [-0.1586,  0.0021,  0.0858,  ...,  0.0097,  0.0323,  0.0714],\n",
      "        [-0.4907,  0.0552,  0.0380,  ..., -0.0711, -0.0339, -0.0136]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.feedforward.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('<pad>', 0), ('M', 1), ('R', 2), ('H', 3), ('K', 4), ('D', 5), ('E', 6), ('S', 7), ('T', 8), ('N', 9), ('Q', 10), ('C', 11), ('U', 12), ('G', 13), ('P', 14), ('A', 15), ('V', 16), ('I', 17), ('F', 18), ('Y', 19), ('W', 20), ('L', 21), ('O', 22), ('X', 23), ('Z', 23), ('B', 23), ('J', 23), ('<cls>', 24), ('<sep>', 25)])\n",
      "tensor([[24, 13, 11,  8, 16,  6,  5, 25]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[  4.7122,  -0.9693,  -1.7770,  -0.9777,  -1.5403,  -1.2578,  -1.0279,\n",
       "            -1.2994,  -1.1935,  -1.3617,  -2.1368, -10.2135,  -0.9097,  -0.9102,\n",
       "            -0.7804,  -0.9665,  -1.1355,  -1.1997,  -1.4462,  -2.5935,  -0.3936,\n",
       "           -10.4988, -10.9553, -10.3032,  -6.3302],\n",
       "          [ -2.1055,  -0.8174,  -2.0496,  -0.8736,  -1.3527,  -0.9619,  -0.6972,\n",
       "            -1.0954,  -1.4274,  -1.6354,  -2.1289, -12.5411,  -0.4415,  -0.9722,\n",
       "            -0.6240,  -0.8490,  -1.0964,  -1.5946,  -2.0409,  -2.3955,  -0.4821,\n",
       "           -13.4826, -13.4685, -13.4728,  -4.6399],\n",
       "          [ -2.4944,  -1.1877,  -2.1952,  -1.7645,  -1.5720,  -1.6680,  -0.8755,\n",
       "            -1.5376,  -1.8708,  -2.0873,  -1.7326, -13.1058,  -0.7995,  -1.2540,\n",
       "            -1.1414,  -1.3046,  -1.6317,  -1.5870,  -2.0093,  -2.4680,  -0.9934,\n",
       "           -13.9631, -14.0157, -13.8544,  -4.1981],\n",
       "          [ -2.2567,  -1.3499,  -2.1782,  -1.6112,  -1.5732,  -1.5904,  -0.8524,\n",
       "            -1.1852,  -1.6349,  -1.8430,  -1.6282, -13.3041,  -0.8735,  -1.2768,\n",
       "            -0.8888,  -1.1233,  -1.4021,  -1.5778,  -1.7863,  -2.4606,  -0.9594,\n",
       "           -14.0439, -14.1587, -14.0549,  -4.7133],\n",
       "          [ -2.5149,  -1.3784,  -2.3319,  -1.6385,  -1.5458,  -1.5095,  -0.9366,\n",
       "            -1.2114,  -1.7476,  -1.8961,  -1.7522, -13.2854,  -1.0784,  -1.4738,\n",
       "            -1.1023,  -1.2237,  -1.6029,  -1.7650,  -1.9444,  -2.7017,  -1.0162,\n",
       "           -13.7269, -13.9551, -13.8997,  -4.6361],\n",
       "          [ -2.6099,  -1.8384,  -2.5990,  -1.8489,  -1.5992,  -1.1970,  -1.5608,\n",
       "            -1.5857,  -1.9211,  -1.7859,  -2.6809, -14.4084,  -1.3403,  -1.9837,\n",
       "            -1.3721,  -1.4042,  -1.7667,  -2.2836,  -2.5246,  -3.2985,  -1.4309,\n",
       "           -14.3430, -14.6222, -14.5927,  -5.7800],\n",
       "          [ -2.6617,  -2.1576,  -3.2913,  -2.3084,  -2.0494,  -1.8592,  -1.9761,\n",
       "            -2.1318,  -2.5997,  -2.7641,  -2.6783, -17.4570,  -1.7294,  -2.2353,\n",
       "            -1.4323,  -1.3378,  -1.5782,  -2.0952,  -2.4739,  -3.1934,  -1.2063,\n",
       "           -17.8181, -17.9741, -17.9622,  -5.6325],\n",
       "          [  3.8239, -12.7875,  -6.4221, -14.6402,  -6.8115, -10.8846,  -2.3906,\n",
       "             1.8045,  -7.3279,  -8.8587,   2.6907, -34.8316,  -1.6237, -12.9601,\n",
       "             5.1303,   6.0588,   2.9431,   1.8708,  -4.2061,  -3.4064,   4.7599,\n",
       "           -37.8826, -37.7638, -37.2135, -50.1512]]]),)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "print(tokenizer.vocab)\n",
    "seq = 'GCTVED'\n",
    "\n",
    "token_ids = torch.tensor(np.array([tokenizer.encode(seq)]))\n",
    "print(token_ids)\n",
    "with torch.no_grad():\n",
    "    output = model(token_ids)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hopper_tape_rao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
