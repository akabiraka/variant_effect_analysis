{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "home_dir = \"../../\"\n",
    "module_path = os.path.abspath(os.path.join(home_dir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models.aa_common.performance_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"popu_freq\"\n",
    "model_root_and_name_tuple_list = [(\"dbnsfp\", \"sift\"), (\"dbnsfp\", \"polyphen2_HVAR\"), (\"dbnsfp\", \"cadd\"), (\"dbnsfp\", \"mvp\"), (\"dbnsfp\", \"metarnn\"), (\"dbnsfp\", \"revel\"),\n",
    "                                  (\"tape_rao\", \"unirep\"), (\"tape_rao\", \"protbert\"), (\"sequnet_dunham\", \"sequnet\"), \n",
    "                                  (\"esm_rives\", \"esm1b_t33_650M_UR50S\"), (\"esm_rives\", \"esm1v_t33_650M_UR90S\"), (\"esm_rives\", \"esm2_t33_650M_UR50D\"),\n",
    "                                  (\"bioembeddings_dallago\", \"plus_rnn\"), \n",
    "                                  (\"bioembeddings_dallago\", \"prottrans_bert_bfd\"), (\"bioembeddings_dallago\", \"prottrans_albert_bfd\"),\n",
    "                                  (\"bioembeddings_dallago\", \"prottrans_xlnet_uniref100\"), \n",
    "                                  (\"bioembeddings_dallago\", \"prottrans_t5_bfd\"), (\"bioembeddings_dallago\", \"prottrans_t5_uniref50\"), (\"bioembeddings_dallago\", \"prottrans_t5_xl_u50\")]\n",
    "\n",
    "metrics = [\"AUC-ROC\", \"AUC-PR\", \"F1-max\", \"Th-max\", \"Precision\", \"Recall\", \"Accuracy\", \"Balanced-accuracy\", \"MCC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47662, 33)\n",
      "Index(['snp_id', 'chrom_acc_version', 'chrom_pos', 'ref_allele', 'alt_allele',\n",
      "       'prot_acc_version', 'prot_pos', 'wt', 'mut', 'wt_population',\n",
      "       'mut_poulation', 'wt_freq', 'mt_freq', 'class', 'sift_pred',\n",
      "       'polyphen2_HVAR_pred', 'cadd_pred', 'mvp_pred', 'metarnn_pred',\n",
      "       'revel_pred', 'unirep_pred', 'protbert_pred', 'sequnet_pred',\n",
      "       'esm1b_t33_650M_UR50S_pred', 'esm1v_t33_650M_UR90S_pred',\n",
      "       'esm2_t33_650M_UR50D_pred', 'plus_rnn_pred', 'prottrans_bert_bfd_pred',\n",
      "       'prottrans_albert_bfd_pred', 'prottrans_xlnet_uniref100_pred',\n",
      "       'prottrans_t5_bfd_pred', 'prottrans_t5_uniref50_pred',\n",
      "       'prottrans_t5_xl_u50_pred'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.read_csv(home_dir+f\"models/aa_common/merged_predictions/{task}_analysis.csv\", sep=\"\\t\")\n",
    "result_df = result_df[result_df[\"mt_freq\"]>=.001] # common and rare only\n",
    "print(result_df.shape)\n",
    "print(result_df.columns)\n",
    "\n",
    "result_df.loc[result_df[\"mt_freq\"]>=.01, \"class\"] = \"Common\"\n",
    "result_df.loc[(result_df[\"mt_freq\"]<.01) & (result_df[\"mt_freq\"]>=.001), \"class\"] = \"Rare\"\n",
    "\n",
    "result_df.loc[result_df[\"class\"]==\"Common\", \"class_numeric\"] = 0\n",
    "result_df.loc[result_df[\"class\"]==\"Rare\", \"class_numeric\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sift\n",
      "\tAUC-ROC: 0.609\n",
      "\tAUC-PR: 0.570\n",
      "\tBest F1-Score: 0.775 at threshold: 0.000\n",
      "\tPrecision score: 0.632 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.632 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n",
      "polyphen2_HVAR\n",
      "\tAUC-ROC: 0.609\n",
      "\tAUC-PR: 0.705\n",
      "\tBest F1-Score: 0.774 at threshold: 0.000\n",
      "\tPrecision score: 0.632 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.632 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n",
      "cadd\n",
      "\tAUC-ROC: 0.608\n",
      "\tAUC-PR: 0.710\n",
      "\tBest F1-Score: 0.771 at threshold: 0.120\n",
      "\tPrecision score: 0.627 at threshold: 0.120\n",
      "\tRecall score: 1.000 at threshold: 0.120\n",
      "\tAccuracy score: 0.627 at threshold: 0.120\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.120\n",
      "\tMCC score: 0.016 at threshold: 0.120\n",
      "mvp\n",
      "\tAUC-ROC: 0.592\n",
      "\tAUC-PR: 0.909\n",
      "\tBest F1-Score: 0.939 at threshold: 0.000\n",
      "\tPrecision score: 0.886 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.886 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n",
      "metarnn\n",
      "\tAUC-ROC: 0.758\n",
      "\tAUC-PR: 0.791\n",
      "\tBest F1-Score: 0.819 at threshold: 0.002\n",
      "\tPrecision score: 0.723 at threshold: 0.002\n",
      "\tRecall score: 0.945 at threshold: 0.002\n",
      "\tAccuracy score: 0.738 at threshold: 0.002\n",
      "\tBalanced accuracy score: 0.668 at threshold: 0.002\n",
      "\tMCC score: 0.422 at threshold: 0.002\n",
      "revel\n",
      "\tAUC-ROC: 0.579\n",
      "\tAUC-PR: 0.708\n",
      "\tBest F1-Score: 0.774 at threshold: 0.000\n",
      "\tPrecision score: 0.631 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.631 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n",
      "unirep\n",
      "\tAUC-ROC: 0.520\n",
      "\tAUC-PR: 0.600\n",
      "\tBest F1-Score: 0.763 at threshold: 0.001\n",
      "\tPrecision score: 0.616 at threshold: 0.001\n",
      "\tRecall score: 1.000 at threshold: 0.001\n",
      "\tAccuracy score: 0.617 at threshold: 0.001\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.001\n",
      "\tMCC score: 0.006 at threshold: 0.001\n",
      "protbert\n",
      "\tAUC-ROC: 0.531\n",
      "\tAUC-PR: 0.590\n",
      "\tBest F1-Score: 0.763 at threshold: 0.000\n",
      "\tPrecision score: 0.616 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.616 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n",
      "sequnet\n",
      "\tAUC-ROC: 0.516\n",
      "\tAUC-PR: 0.628\n",
      "\tBest F1-Score: 0.763 at threshold: 0.000\n",
      "\tPrecision score: 0.616 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.616 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n",
      "esm1b_t33_650M_UR50S\n",
      "\tAUC-ROC: 0.565\n",
      "\tAUC-PR: 0.562\n",
      "\tBest F1-Score: 0.763 at threshold: 0.000\n",
      "\tPrecision score: 0.616 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.616 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n",
      "esm1v_t33_650M_UR90S\n",
      "\tAUC-ROC: 0.559\n",
      "\tAUC-PR: 0.567\n",
      "\tBest F1-Score: 0.763 at threshold: 0.000\n",
      "\tPrecision score: 0.616 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.616 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n",
      "esm2_t33_650M_UR50D\n",
      "\tAUC-ROC: 0.561\n",
      "\tAUC-PR: 0.566\n",
      "\tBest F1-Score: 0.763 at threshold: 0.055\n",
      "\tPrecision score: 0.616 at threshold: 0.055\n",
      "\tRecall score: 1.000 at threshold: 0.055\n",
      "\tAccuracy score: 0.617 at threshold: 0.055\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.055\n",
      "\tMCC score: 0.006 at threshold: 0.055\n",
      "plus_rnn\n",
      "\tAUC-ROC: 0.529\n",
      "\tAUC-PR: 0.591\n",
      "\tBest F1-Score: 0.763 at threshold: 0.031\n",
      "\tPrecision score: 0.616 at threshold: 0.031\n",
      "\tRecall score: 1.000 at threshold: 0.031\n",
      "\tAccuracy score: 0.617 at threshold: 0.031\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.031\n",
      "\tMCC score: 0.006 at threshold: 0.031\n",
      "prottrans_bert_bfd\n",
      "\tAUC-ROC: 0.542\n",
      "\tAUC-PR: 0.578\n",
      "\tBest F1-Score: 0.763 at threshold: 0.000\n",
      "\tPrecision score: 0.616 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.616 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n",
      "prottrans_albert_bfd\n",
      "\tAUC-ROC: 0.559\n",
      "\tAUC-PR: 0.566\n",
      "\tBest F1-Score: 0.763 at threshold: 0.036\n",
      "\tPrecision score: 0.617 at threshold: 0.036\n",
      "\tRecall score: 1.000 at threshold: 0.036\n",
      "\tAccuracy score: 0.617 at threshold: 0.036\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.036\n",
      "\tMCC score: 0.005 at threshold: 0.036\n",
      "prottrans_xlnet_uniref100\n",
      "\tAUC-ROC: 0.532\n",
      "\tAUC-PR: 0.589\n",
      "\tBest F1-Score: 0.763 at threshold: 0.145\n",
      "\tPrecision score: 0.617 at threshold: 0.145\n",
      "\tRecall score: 1.000 at threshold: 0.145\n",
      "\tAccuracy score: 0.617 at threshold: 0.145\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.145\n",
      "\tMCC score: 0.010 at threshold: 0.145\n",
      "prottrans_t5_bfd\n",
      "\tAUC-ROC: 0.507\n",
      "\tAUC-PR: 0.615\n",
      "\tBest F1-Score: 0.763 at threshold: 0.000\n",
      "\tPrecision score: 0.616 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.616 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n",
      "prottrans_t5_uniref50\n",
      "\tAUC-ROC: 0.509\n",
      "\tAUC-PR: 0.613\n",
      "\tBest F1-Score: 0.763 at threshold: 0.000\n",
      "\tPrecision score: 0.616 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.616 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n",
      "prottrans_t5_xl_u50\n",
      "\tAUC-ROC: 0.509\n",
      "\tAUC-PR: 0.612\n",
      "\tBest F1-Score: 0.763 at threshold: 0.000\n",
      "\tPrecision score: 0.616 at threshold: 0.000\n",
      "\tRecall score: 1.000 at threshold: 0.000\n",
      "\tAccuracy score: 0.616 at threshold: 0.000\n",
      "\tBalanced accuracy score: 0.500 at threshold: 0.000\n",
      "\tMCC score: 0.000 at threshold: 0.000\n"
     ]
    }
   ],
   "source": [
    "output_file = home_dir+f\"models/aa_common/performance_analysis/{task}.csv\"\n",
    "\n",
    "out = open(output_file, 'w')\n",
    "out.write(\"Models\\\\Metrics\")\n",
    "for metric in metrics:\n",
    "    out.write(f\"\\t{metric}\")\n",
    "out.write(\"\\n\")\n",
    "\n",
    "for i, (model_root, model_name) in enumerate(model_root_and_name_tuple_list):\n",
    "    print(model_name)\n",
    "    model_pred_col = model_name + \"_pred\"\n",
    "    result_df[\"pred\"]=(result_df[model_pred_col]-result_df[model_pred_col].min())/(result_df[model_pred_col].max()-result_df[model_pred_col].min()) # scaling prediction scores between [0, 1]\n",
    "    \n",
    "    non_nan_result_df = result_df[~pd.isna(result_df[model_pred_col])]  # taking df for only non-NAN values\n",
    "    \n",
    "    auc_roc_score = get_auc_roc_score(non_nan_result_df)\n",
    "    auc_pr_score, precisions, recalls, thresholds = get_auc_pr_score(non_nan_result_df)\n",
    "    f1_max, th_max = get_f1max_and_th(precisions, recalls, thresholds)\n",
    "    precision = get_precision_score(non_nan_result_df, th_max)\n",
    "    recall = get_recall_score(non_nan_result_df, th_max)\n",
    "    accuracy = get_accuracy_score(non_nan_result_df, th_max)\n",
    "    balanced_accuracy = get_balanced_accuracy_score(non_nan_result_df, th_max)\n",
    "    mcc = get_matthews_corrcoef(non_nan_result_df, th_max)\n",
    "    \n",
    "    permformance_scores = [auc_roc_score, auc_pr_score, f1_max, th_max, precision, recall, accuracy, balanced_accuracy, mcc]\n",
    "    \n",
    "    out.write(f\"{model_name}\")\n",
    "    for score in permformance_scores:\n",
    "        out.write(f\"\\t{score:.3f}\")\n",
    "    out.write(\"\\n\")\n",
    "        \n",
    "    \n",
    "    # if i==5: break\n",
    "\n",
    "out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hopper_variant_effect_analysis_mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
