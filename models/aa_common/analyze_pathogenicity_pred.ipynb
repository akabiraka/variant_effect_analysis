{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "home_dir = \"../../\"\n",
    "module_path = os.path.abspath(os.path.join(home_dir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathogenicity_type = \"pathogenic\" # pathogenic, likely_pathogenic\n",
    "\n",
    "# root_model = \"tape_rao\"\n",
    "# model_name = \"protbert\" # unirep, protbert\n",
    "\n",
    "# root_model = \"sequnet_dunham\"\n",
    "# model_name = \"sequnet\"\n",
    "\n",
    "# root_model = \"esm_rives\"\n",
    "# model_name = \"esm2_t33_650M_UR50D\" # esm1b_t33_650M_UR50S, esm1v_t33_650M_UR90S, esm2_t33_650M_UR50D\n",
    "\n",
    "root_model = \"bioembeddings_dallago\"\n",
    "model_name = \"prottrans_t5_xl_u50\" # plus_rnn, prottrans_bert_bfd, prottrans_albert_bfd, prottrans_xlnet_uniref100, prottrans_t5_bfd, prottrans_t5_uniref50, prottrans_t5_xl_u50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_distritution_boxplot(result_df):\n",
    "    fg = sns.catplot(data=result_df, x=\"pred\", y=\"class\", order=[pathogenicity_type, \"neutral\",], kind=\"box\")\n",
    "    # fg.set_xlabels(\"Prediction scores\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(result_df):\n",
    "    pathogenic = result_df[result_df[\"class\"]==pathogenicity_type]\n",
    "    neutral = result_df[result_df[\"class\"]==\"neutral\"]\n",
    "\n",
    "    # pathogenic_pred_normalized=(pathogenic[\"pred\"]-pathogenic[\"pred\"].min())/(pathogenic[\"pred\"].max()-pathogenic[\"pred\"].min())\n",
    "    # neutral_pred_normalized=(neutral[\"pred\"]-neutral[\"pred\"].min())/(neutral[\"pred\"].max()-neutral[\"pred\"].min())\n",
    "\n",
    "    bins = 100 # 20, 100, 500\n",
    "    # plt.hist(pathogenic_pred_normalized, bins=bins, density=True, log=True, alpha=.5, label=f\"Pathogenic-{model_name}\")\n",
    "    # plt.hist(neutral_pred_normalized, bins=bins, density=True, log=True, alpha=.5, label=f\"Neutral-{model_name}\")\n",
    "\n",
    "    # print(result_df[\"class\"])\n",
    "    plt.hist(pathogenic[\"pred\"], bins=bins, density=False, log=False, alpha=.6, label=f\"{pathogenicity_type}-{model_name}\")\n",
    "    plt.hist(neutral[\"pred\"], bins=bins, density=False, log=False, alpha=.4, label=f\"neutral-{model_name}\")\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509\n",
      "0.501\n",
      "0.508\n",
      "0.504\n",
      "0.501\n",
      "0.512\n",
      "0.505\n",
      "0.503\n",
      "0.510\n",
      "0.503\n",
      "0.506\n"
     ]
    }
   ],
   "source": [
    "aucs = []\n",
    "for analysis_no in range(10):\n",
    "    result_df = pd.read_csv(home_dir+f\"models/{root_model}/outputs/{model_name}/{pathogenicity_type}/{str(analysis_no)}.csv\", sep=\"\\t\")\n",
    "\n",
    "    # this has no effect on the metric, but required for plotting the fig in the same x-axis scale.\n",
    "    result_df[\"pred\"]=(result_df[\"pred\"]-result_df[\"pred\"].min())/(result_df[\"pred\"].max()-result_df[\"pred\"].min())\n",
    "\n",
    "    result_df.loc[result_df[\"class\"]==pathogenicity_type, \"class_numeric\"] = 0\n",
    "    result_df.loc[result_df[\"class\"]==\"neutral\", \"class_numeric\"] = 1\n",
    "\n",
    "    # score = roc_auc_score(result_df[\"class\"], result_df[\"pred\"])\n",
    "    # if score < 0.5: \n",
    "    #     score = 1 - score\n",
    "    # print(f\"{score:.3f}\")\n",
    "    # aucs.append(score)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(result_df[\"class_numeric\"], result_df[\"pred\"])\n",
    "    score = auc(recall, precision)\n",
    "    if score < 0.5: \n",
    "        score = 1 - score\n",
    "    print(f\"{score:.3f}\")\n",
    "    aucs.append(score)\n",
    "\n",
    "\n",
    "    # plot_distribution(result_df)\n",
    "    # plot_distritution_boxplot(result_df)\n",
    "    \n",
    "    # break\n",
    "\n",
    "print(f\"{np.mean(aucs):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hopper_tape_rao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
