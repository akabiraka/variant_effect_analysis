{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "home_dir = \"../../\"\n",
    "module_path = os.path.abspath(os.path.join(home_dir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 128) (333, 128)\n",
      "[-18.4878    -22.949091  -38.26504    -7.300834   -6.658306   -7.0187225\n",
      "  -7.0971704  -5.225935   -6.947036   -8.462962   -7.6526833  -6.9689527\n",
      "  -7.2655077  -8.009003   -8.329077   -5.4901075  -7.926539   -6.5617867\n",
      "  -5.6144943  -7.9192348  -7.335067   -6.939086    0.9607053  -9.994657\n",
      " -38.907906  -38.88283   -38.507957  -38.34755   -38.25691   -38.697487\n",
      " -38.068604  -38.78185   -38.315678  -38.91271   -38.62858   -39.077114\n",
      " -38.514313  -38.23457   -38.610947  -38.90276   -37.73464   -38.958107\n",
      " -38.64975   -38.593254  -37.579292  -38.18425   -38.490196  -37.573486\n",
      " -38.19103   -38.179268  -38.261032  -38.80136   -38.286304  -37.806274\n",
      " -38.77648   -38.126602  -37.6558    -38.057735  -38.742058  -37.88672\n",
      " -38.151596  -37.99424   -38.314735  -38.346714  -37.75525   -38.61832\n",
      " -37.549538  -38.103226  -38.064907  -38.97631   -38.82532   -38.775043\n",
      " -38.872723  -38.65758   -38.139046  -37.507587  -38.24138   -38.8613\n",
      " -38.193134  -38.623577  -38.581158  -38.878036  -37.990417  -38.562096\n",
      " -38.632626  -37.941433  -38.385696  -38.699047  -38.1212    -38.514008\n",
      " -37.86189   -38.74111   -38.300613  -38.640263  -37.947495  -37.66608\n",
      " -38.74791   -38.612316  -38.26177   -39.080513  -38.02367   -38.317886\n",
      " -38.122513  -38.06784   -38.103245  -38.10182   -38.56096   -37.628567\n",
      " -38.36936   -38.68828   -38.176975  -38.582405  -37.973133  -38.3021\n",
      " -37.73491   -38.293564  -37.7916    -38.336136  -38.52157   -38.06826\n",
      " -38.755592  -37.574818  -38.69241   -38.595985  -38.500336  -37.929424\n",
      " -38.050064  -18.349163 ]\n",
      "[-24.805634   -42.95871    -69.69945    -22.445004   -24.132124\n",
      " -19.923153   -21.443977   -22.879719   -25.238049   -29.867584\n",
      " -26.72593    -24.299404   -23.760939   -21.024345   -27.945965\n",
      " -22.016909   -27.530052   -24.880142   -22.3163     -24.51819\n",
      " -21.261044   -21.11567      0.95099735 -26.607548   -71.047905\n",
      " -70.361435   -70.26103    -69.714355   -69.52471    -70.314865\n",
      " -69.52724    -70.399185   -69.768616   -70.925674   -70.18953\n",
      " -70.97332    -70.609344   -69.70358    -70.3094     -70.88855\n",
      " -68.82802    -70.91609    -70.0076     -70.62024    -68.77588\n",
      " -70.10199    -70.47037    -68.967834   -69.48552    -69.79395\n",
      " -69.94504    -70.47162    -69.651276   -68.41932    -70.75929\n",
      " -70.584526   -68.20264    -69.353035   -70.43417    -69.39634\n",
      " -69.78909    -69.38207    -70.18764    -70.149445   -68.632126\n",
      " -69.78136    -68.19031    -69.60612    -69.39688    -70.82677\n",
      " -70.39686    -70.52753    -70.676384   -70.13736    -69.5214\n",
      " -67.95318    -69.38041    -70.830025   -69.609344   -70.12151\n",
      " -69.995865   -70.79117    -69.67288    -70.21031    -70.6388\n",
      " -69.43451    -69.801155   -70.23318    -69.37344    -70.20938\n",
      " -69.65657    -70.7855     -69.73218    -70.29146    -69.38158\n",
      " -68.51422    -70.88383    -70.432884   -69.851074   -71.25565\n",
      " -69.1129     -70.10916    -70.1948     -68.56829    -69.127625\n",
      " -69.35831    -70.37179    -68.106186   -70.266396   -70.5553\n",
      " -69.3163     -70.35953    -69.18198    -70.17262    -68.75154\n",
      " -69.87705    -69.21499    -69.83768    -70.63307    -69.12775\n",
      " -70.989975   -68.09081    -70.404236   -70.39224    -70.397545\n",
      " -69.5381     -69.88995    -30.787323  ]\n"
     ]
    }
   ],
   "source": [
    "# does masking change the logits: yes.\n",
    "# loading logits from from same seq but masked in different position.\n",
    "import utils.pickle_utils as pickle_utils\n",
    "logits_1 = pickle_utils.load_pickle(home_dir+f\"models/vespa_marquet/outputs/vespa/lm_outputs/A000006_2_271.pkl\") \n",
    "logits_2 = pickle_utils.load_pickle(home_dir+f\"models/vespa_marquet/outputs/vespa/lm_outputs/A000006_2_62.pkl\") \n",
    "print(logits_1.shape, logits_2.shape)\n",
    "# now see, logits in masked position are different, \n",
    "print(logits_1[270])\n",
    "print(logits_2[270])\n",
    "# but non-masked position are same.\n",
    "# print(logits_1[1])\n",
    "# print(logits_2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/ashehu/akabir4/venvs/hopper_vespa_marquet_from_source/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from vespa.predict.logodds import *\n",
    "import vespa.predict.utils as vespa_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir=home_dir+\"models/vespa_marquet/cache\"\n",
    "t5_condProbas = T5_condProbas(cache_dir=cache_dir)\n",
    "model, tokenizer = t5_condProbas.prott5.get_model(1) #1=LOGODDS\n",
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Tokenizer(name_or_path='Rostlab/prot_t5_xl_uniref50', vocab_size=128, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  3,   7, 127,  23,   1]])\n",
      "(5, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.91068115e+01, -5.45365448e+01, -7.43222656e+01,\n",
       "        -2.02146411e+00, -2.19304924e+01, -1.98203201e+01,\n",
       "        -2.22698174e+01, -2.00179672e+01, -2.14014206e+01,\n",
       "        -2.21622543e+01, -2.11345768e+01, -2.14733925e+01,\n",
       "        -2.40762138e+01, -2.05142231e+01, -2.18514900e+01,\n",
       "        -2.42242603e+01, -2.24806061e+01, -2.35430584e+01,\n",
       "        -2.35312500e+01, -2.45066071e+01, -2.52229252e+01,\n",
       "        -2.41816750e+01, -2.13377533e+01, -2.55332565e+01,\n",
       "        -7.47518234e+01, -7.44212494e+01, -7.50349884e+01,\n",
       "        -7.47520218e+01, -7.39672470e+01, -7.48720551e+01,\n",
       "        -7.42906189e+01, -7.42783508e+01, -7.42578201e+01,\n",
       "        -7.53950958e+01, -7.42682495e+01, -7.47694397e+01,\n",
       "        -7.53383789e+01, -7.42927399e+01, -7.40554199e+01,\n",
       "        -7.51404114e+01, -7.35035400e+01, -7.51246033e+01,\n",
       "        -7.51932297e+01, -7.48868179e+01, -7.43903046e+01,\n",
       "        -7.51347809e+01, -7.44550018e+01, -7.40901337e+01,\n",
       "        -7.35273819e+01, -7.46163559e+01, -7.46038208e+01,\n",
       "        -7.46174774e+01, -7.41651077e+01, -7.41930847e+01,\n",
       "        -7.54778748e+01, -7.49373016e+01, -7.35331879e+01,\n",
       "        -7.38238525e+01, -7.48920822e+01, -7.42707520e+01,\n",
       "        -7.47747116e+01, -7.38981628e+01, -7.50545349e+01,\n",
       "        -7.47776794e+01, -7.35868301e+01, -7.43485718e+01,\n",
       "        -7.34467087e+01, -7.41810837e+01, -7.41709290e+01,\n",
       "        -7.54916077e+01, -7.50397186e+01, -7.44065475e+01,\n",
       "        -7.51083832e+01, -7.42126083e+01, -7.44221954e+01,\n",
       "        -7.37823639e+01, -7.41752472e+01, -7.45070801e+01,\n",
       "        -7.52019958e+01, -7.48563995e+01, -7.44624710e+01,\n",
       "        -7.49257050e+01, -7.50419464e+01, -7.52386169e+01,\n",
       "        -7.60173798e+01, -7.48642578e+01, -7.43445206e+01,\n",
       "        -7.50155334e+01, -7.47224503e+01, -7.43855133e+01,\n",
       "        -7.41715240e+01, -7.49946060e+01, -7.42662201e+01,\n",
       "        -7.49128571e+01, -7.43502884e+01, -7.32761230e+01,\n",
       "        -7.49715576e+01, -7.52225952e+01, -7.47157516e+01,\n",
       "        -7.56545944e+01, -7.37234955e+01, -7.56608047e+01,\n",
       "        -7.57750702e+01, -7.40067291e+01, -7.41561661e+01,\n",
       "        -7.36824265e+01, -7.45624619e+01, -7.33726120e+01,\n",
       "        -7.52543259e+01, -7.47543030e+01, -7.38833313e+01,\n",
       "        -7.46038589e+01, -7.33287811e+01, -7.51189423e+01,\n",
       "        -7.34935608e+01, -7.37845001e+01, -7.35951004e+01,\n",
       "        -7.37177582e+01, -7.48512573e+01, -7.35444336e+01,\n",
       "        -7.53498077e+01, -7.38499451e+01, -7.53510284e+01,\n",
       "        -7.42439346e+01, -7.42454834e+01, -7.41783142e+01,\n",
       "        -7.45285568e+01, -4.55639496e+01],\n",
       "       [-3.79732666e+01, -5.88687057e+01, -1.00748291e+02,\n",
       "        -2.07899475e+01, -2.21362152e+01, -2.14503670e+01,\n",
       "        -2.27978668e+01, -4.13882923e+00, -2.27570877e+01,\n",
       "        -2.22400818e+01, -2.21827431e+01, -2.15553551e+01,\n",
       "        -2.32414665e+01, -2.23475132e+01, -2.29570446e+01,\n",
       "        -2.25946999e+01, -2.24035530e+01, -2.16779995e+01,\n",
       "        -2.32761211e+01, -2.43323212e+01, -2.38240623e+01,\n",
       "        -2.60013657e+01, -2.30435905e+01, -2.37888927e+01,\n",
       "        -1.02082214e+02, -1.01842484e+02, -1.01563080e+02,\n",
       "        -1.01565994e+02, -1.01061661e+02, -1.02184891e+02,\n",
       "        -1.01644615e+02, -1.01506836e+02, -1.01277771e+02,\n",
       "        -1.02422882e+02, -1.02290436e+02, -1.02416527e+02,\n",
       "        -1.02108368e+02, -1.01193741e+02, -1.02049240e+02,\n",
       "        -1.02187180e+02, -1.00641937e+02, -1.02365707e+02,\n",
       "        -1.02255180e+02, -1.02561157e+02, -1.01571480e+02,\n",
       "        -1.02184830e+02, -1.01960388e+02, -1.00844688e+02,\n",
       "        -1.01167709e+02, -1.01711861e+02, -1.01746674e+02,\n",
       "        -1.01758392e+02, -1.01322144e+02, -1.01266235e+02,\n",
       "        -1.02598869e+02, -1.02135696e+02, -9.99019547e+01,\n",
       "        -1.00627625e+02, -1.02632599e+02, -1.01409447e+02,\n",
       "        -1.01643227e+02, -1.02303169e+02, -1.02227760e+02,\n",
       "        -1.01596916e+02, -1.00177185e+02, -1.01774734e+02,\n",
       "        -1.00473801e+02, -1.01186493e+02, -1.01099045e+02,\n",
       "        -1.03479462e+02, -1.02359970e+02, -1.01962799e+02,\n",
       "        -1.01724297e+02, -1.01593193e+02, -1.00995697e+02,\n",
       "        -1.00668633e+02, -1.01674240e+02, -1.01848412e+02,\n",
       "        -1.01826462e+02, -1.02365791e+02, -1.01479317e+02,\n",
       "        -1.01605469e+02, -1.01694374e+02, -1.02395767e+02,\n",
       "        -1.03027267e+02, -1.01852402e+02, -1.02077171e+02,\n",
       "        -1.02249054e+02, -1.01311638e+02, -1.02003456e+02,\n",
       "        -1.01453102e+02, -1.02517174e+02, -1.00873581e+02,\n",
       "        -1.02074478e+02, -1.01163605e+02, -1.00394577e+02,\n",
       "        -1.02504547e+02, -1.02377579e+02, -1.01657555e+02,\n",
       "        -1.02519913e+02, -1.00727814e+02, -1.02332397e+02,\n",
       "        -1.01997772e+02, -1.00661346e+02, -1.01293335e+02,\n",
       "        -1.01567398e+02, -1.01528931e+02, -1.00635445e+02,\n",
       "        -1.02012299e+02, -1.01971329e+02, -1.00816299e+02,\n",
       "        -1.01084396e+02, -1.00809525e+02, -1.01896652e+02,\n",
       "        -1.01653809e+02, -1.01442886e+02, -1.00981918e+02,\n",
       "        -1.01103226e+02, -1.01893532e+02, -1.01231323e+02,\n",
       "        -1.02419510e+02, -1.00793449e+02, -1.01871140e+02,\n",
       "        -1.01882919e+02, -1.01348984e+02, -1.00831696e+02,\n",
       "        -1.01306442e+02, -4.57615128e+01],\n",
       "       [-9.35614491e+00, -1.28522711e+01, -2.71158485e+01,\n",
       "        -1.94168508e-01, -4.47422326e-01, -3.52392465e-01,\n",
       "        -8.42351437e-01, -8.17505196e-02, -4.25318241e-01,\n",
       "        -9.47988272e-01, -1.18533599e+00, -7.27293849e-01,\n",
       "        -1.24459696e+00, -6.90936685e-01, -6.93311572e-01,\n",
       "        -1.41398489e+00, -1.21301210e+00, -1.31264138e+00,\n",
       "        -1.94057858e+00, -2.14820576e+00, -1.91576576e+00,\n",
       "        -2.26171041e+00, -1.98073435e+00, -6.85797930e-02,\n",
       "        -2.74720173e+01, -2.75557022e+01, -2.73324738e+01,\n",
       "        -2.71333561e+01, -2.67625275e+01, -2.74553204e+01,\n",
       "        -2.69351273e+01, -2.74416580e+01, -2.70596066e+01,\n",
       "        -2.74492378e+01, -2.73918190e+01, -2.75571518e+01,\n",
       "        -2.72227783e+01, -2.70123920e+01, -2.73758316e+01,\n",
       "        -2.74668388e+01, -2.65678406e+01, -2.73632011e+01,\n",
       "        -2.73759079e+01, -2.73550301e+01, -2.65656815e+01,\n",
       "        -2.68096733e+01, -2.71637878e+01, -2.62632885e+01,\n",
       "        -2.69519348e+01, -2.68735371e+01, -2.69770107e+01,\n",
       "        -2.74543095e+01, -2.69788609e+01, -2.64905891e+01,\n",
       "        -2.73550682e+01, -2.70040607e+01, -2.67943287e+01,\n",
       "        -2.68326111e+01, -2.73970757e+01, -2.70341587e+01,\n",
       "        -2.70883961e+01, -2.66649933e+01, -2.72841110e+01,\n",
       "        -2.70061493e+01, -2.65437431e+01, -2.73160152e+01,\n",
       "        -2.63709850e+01, -2.66090279e+01, -2.69471855e+01,\n",
       "        -2.74597149e+01, -2.72993736e+01, -2.75570431e+01,\n",
       "        -2.76043396e+01, -2.73542404e+01, -2.69189854e+01,\n",
       "        -2.62976723e+01, -2.71488113e+01, -2.75124779e+01,\n",
       "        -2.70378685e+01, -2.72709560e+01, -2.72680130e+01,\n",
       "        -2.72350292e+01, -2.70762234e+01, -2.73023243e+01,\n",
       "        -2.72523270e+01, -2.68436527e+01, -2.70756283e+01,\n",
       "        -2.72735443e+01, -2.70775166e+01, -2.71610565e+01,\n",
       "        -2.66772785e+01, -2.73529930e+01, -2.70063496e+01,\n",
       "        -2.75259857e+01, -2.66849918e+01, -2.64145184e+01,\n",
       "        -2.75222626e+01, -2.73138695e+01, -2.70737114e+01,\n",
       "        -2.74700165e+01, -2.67945404e+01, -2.68665829e+01,\n",
       "        -2.71563683e+01, -2.67195644e+01, -2.68461266e+01,\n",
       "        -2.69289227e+01, -2.72249527e+01, -2.63863926e+01,\n",
       "        -2.71281166e+01, -2.73878632e+01, -2.70504303e+01,\n",
       "        -2.74504948e+01, -2.68928280e+01, -2.71197224e+01,\n",
       "        -2.65025711e+01, -2.69642754e+01, -2.65559082e+01,\n",
       "        -2.70880890e+01, -2.70976868e+01, -2.67585373e+01,\n",
       "        -2.74267464e+01, -2.63952541e+01, -2.73153229e+01,\n",
       "        -2.71957130e+01, -2.72465763e+01, -2.69563942e+01,\n",
       "        -2.70281353e+01, -9.33766365e+00],\n",
       "       [-2.60932121e+01, -2.47159462e+01, -6.16140518e+01,\n",
       "        -2.22141991e+01, -2.35182590e+01, -2.02618484e+01,\n",
       "        -2.05208702e+01, -1.99659386e+01, -2.00684662e+01,\n",
       "        -2.22135620e+01, -2.02874603e+01, -1.92882442e+01,\n",
       "        -1.81906338e+01, -1.92757530e+01, -1.84692307e+01,\n",
       "        -1.84467621e+01, -2.53843594e+01, -1.93236771e+01,\n",
       "        -2.13708839e+01, -2.42506180e+01, -2.26836071e+01,\n",
       "        -2.29223900e+01, -2.02466450e+01,  1.90178871e+00,\n",
       "        -6.20039749e+01, -6.24298172e+01, -6.21651917e+01,\n",
       "        -6.16082611e+01, -6.05942612e+01, -6.24978981e+01,\n",
       "        -6.14363518e+01, -6.19293900e+01, -6.19362259e+01,\n",
       "        -6.26112328e+01, -6.22134857e+01, -6.26128082e+01,\n",
       "        -6.17145424e+01, -6.17376823e+01, -6.22752686e+01,\n",
       "        -6.23987427e+01, -6.09816132e+01, -6.25312157e+01,\n",
       "        -6.21721764e+01, -6.26657104e+01, -6.07973938e+01,\n",
       "        -6.11818924e+01, -6.18394165e+01, -6.04145546e+01,\n",
       "        -6.12330856e+01, -6.12879982e+01, -6.17836380e+01,\n",
       "        -6.24221191e+01, -6.14863739e+01, -6.06267395e+01,\n",
       "        -6.25495911e+01, -6.16111031e+01, -6.05534439e+01,\n",
       "        -6.08181725e+01, -6.25116425e+01, -6.16701660e+01,\n",
       "        -6.18819809e+01, -6.10876045e+01, -6.22923431e+01,\n",
       "        -6.13075829e+01, -6.06012878e+01, -6.16140022e+01,\n",
       "        -5.99757767e+01, -6.04289246e+01, -6.10320396e+01,\n",
       "        -6.30265770e+01, -6.22149773e+01, -6.19667969e+01,\n",
       "        -6.27245865e+01, -6.19716454e+01, -6.11368713e+01,\n",
       "        -5.98808136e+01, -6.18217583e+01, -6.24070358e+01,\n",
       "        -6.17550850e+01, -6.23806381e+01, -6.17048683e+01,\n",
       "        -6.20203094e+01, -6.19996719e+01, -6.19257965e+01,\n",
       "        -6.24664192e+01, -6.15356178e+01, -6.19931259e+01,\n",
       "        -6.21654739e+01, -6.17637405e+01, -6.16806717e+01,\n",
       "        -6.13460617e+01, -6.28206253e+01, -6.10267487e+01,\n",
       "        -6.27495422e+01, -6.05381737e+01, -6.01769562e+01,\n",
       "        -6.26963921e+01, -6.23086166e+01, -6.12227936e+01,\n",
       "        -6.25347786e+01, -6.09280396e+01, -6.18150406e+01,\n",
       "        -6.20588684e+01, -6.08733902e+01, -6.12887688e+01,\n",
       "        -6.11672783e+01, -6.20945396e+01, -6.04188919e+01,\n",
       "        -6.18028946e+01, -6.23752251e+01, -6.14738541e+01,\n",
       "        -6.20327950e+01, -6.06114311e+01, -6.20904160e+01,\n",
       "        -6.02983017e+01, -6.13673248e+01, -6.12982788e+01,\n",
       "        -6.12830429e+01, -6.17970505e+01, -6.09961319e+01,\n",
       "        -6.25303688e+01, -6.01299896e+01, -6.19906883e+01,\n",
       "        -6.16765251e+01, -6.14171944e+01, -6.13452415e+01,\n",
       "        -6.17932701e+01, -3.53047409e+01],\n",
       "       [-2.62662296e+01,  9.51399803e-01, -5.99669304e+01,\n",
       "        -2.07497940e+01, -2.18547020e+01, -1.97005577e+01,\n",
       "        -2.28448448e+01, -2.04521713e+01, -2.07725868e+01,\n",
       "        -1.91686573e+01, -2.05382099e+01, -2.23278770e+01,\n",
       "        -2.39633636e+01, -1.98130760e+01, -1.99259338e+01,\n",
       "        -2.12298775e+01, -2.12314053e+01, -2.23734283e+01,\n",
       "        -2.13779526e+01, -2.32977085e+01, -2.29079895e+01,\n",
       "        -2.11394501e+01, -2.23634796e+01, -1.63355141e+01,\n",
       "        -6.02292404e+01, -6.06549911e+01, -6.02942810e+01,\n",
       "        -5.97259293e+01, -5.88141823e+01, -6.08539429e+01,\n",
       "        -6.00535660e+01, -6.03535538e+01, -6.01400375e+01,\n",
       "        -6.09827957e+01, -6.04029236e+01, -6.06769638e+01,\n",
       "        -5.98827209e+01, -5.98231239e+01, -6.04629745e+01,\n",
       "        -6.04441986e+01, -5.90419006e+01, -6.03347397e+01,\n",
       "        -6.03053169e+01, -6.10396576e+01, -5.89194679e+01,\n",
       "        -5.95942459e+01, -5.97871704e+01, -5.86042633e+01,\n",
       "        -5.98709946e+01, -5.95953064e+01, -5.98165894e+01,\n",
       "        -6.03707962e+01, -5.97477570e+01, -5.91564903e+01,\n",
       "        -6.07298965e+01, -5.99395370e+01, -5.89688568e+01,\n",
       "        -5.89597015e+01, -6.02556953e+01, -6.04775085e+01,\n",
       "        -6.02569809e+01, -5.90167694e+01, -6.04174576e+01,\n",
       "        -6.00514946e+01, -5.85485001e+01, -5.99665146e+01,\n",
       "        -5.82580070e+01, -5.86636734e+01, -5.94891281e+01,\n",
       "        -6.09257507e+01, -6.07035599e+01, -6.07128754e+01,\n",
       "        -6.10825119e+01, -6.03337517e+01, -5.92309952e+01,\n",
       "        -5.79047470e+01, -6.00797424e+01, -6.06549301e+01,\n",
       "        -5.95197525e+01, -6.06776428e+01, -6.00901031e+01,\n",
       "        -6.01802559e+01, -5.97948647e+01, -5.99074783e+01,\n",
       "        -6.01989517e+01, -5.95954514e+01, -6.02640915e+01,\n",
       "        -6.01902237e+01, -5.98175049e+01, -6.01211395e+01,\n",
       "        -5.91187019e+01, -6.08935852e+01, -5.92552071e+01,\n",
       "        -6.07122917e+01, -5.91701317e+01, -5.82876968e+01,\n",
       "        -6.08097458e+01, -6.05195847e+01, -5.96551514e+01,\n",
       "        -6.04612732e+01, -5.92348289e+01, -5.98928032e+01,\n",
       "        -5.99549942e+01, -5.88172913e+01, -5.93409195e+01,\n",
       "        -5.91929016e+01, -6.04524765e+01, -5.86832275e+01,\n",
       "        -5.98845520e+01, -6.09141846e+01, -5.95311127e+01,\n",
       "        -6.02817535e+01, -5.89137573e+01, -6.00552902e+01,\n",
       "        -5.89444504e+01, -5.94521561e+01, -5.94271927e+01,\n",
       "        -6.00587692e+01, -5.99793549e+01, -5.92185822e+01,\n",
       "        -6.08284988e+01, -5.86676064e+01, -5.99389420e+01,\n",
       "        -5.98921280e+01, -6.00357246e+01, -5.95632095e+01,\n",
       "        -5.98209534e+01, -4.22518845e+01]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "seq = \"ASDX\"\n",
    "seq = re.sub(r\"[UZOB]\", \"X\", seq) # replacing unknown amino acids \n",
    "seq = list(seq)\n",
    "seq[2] = \"<extra_id_0>\" # mut_pos should be 0-indexed. replace AA by special mask token used by T5\n",
    "seq = \" \".join(seq)\n",
    "input_ids = tokenizer(seq, return_tensors=\"pt\").input_ids.to(\"cpu\")\n",
    "print(input_ids)\n",
    "with torch.no_grad():  # only logits is useful for us\n",
    "    logits = model(input_ids, labels=input_ids).logits\n",
    "    logits = logits[0].detach().numpy() \n",
    "\n",
    "print(logits.shape)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(\"▁V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'MVNSTHRGMHTSLHLWNRSSYRLHSNASESLGKGYSDGGCYEQLFVSPEVFVTLGVISLLENILVIVAIAKNKNLHSPMYFFICSLAVADMLVSVSNGSETIVITLLNSTDTDAQSFTVNIDNVIDSVICSSLLASICSLLSIAVDRYFTIFYALQYHNIMTVKRVGIIISCIWAACTVSGILFIIYSDSSAVIICLITMFFTMLALMASLYVHMFLMARLHIKRIAVLPGTGAIRQGANMKGAITLTILIGVFVVCWAPFFLHLIFYISCPQNPYCVCFMSHFNLYLILIMCNSIIDPLIYALRSQELRKTFKEIICCYPLGGLCDLSSRY'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "seq_dict = vespa_utils.parse_fasta_input(Path(home_dir+\"models/aa_common/datasets_pmd_analysis/pmd_sequences.fasta\")) # this replaces the unknown amino acids UZO, not B\n",
    "print(len(seq_dict))\n",
    "protid_seq_dict_list = [(prot_id, seq) for prot_id, seq in  seq_dict.items()]\n",
    "protid, seq = protid_seq_dict_list[0]\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.76 GiB total capacity; 9.02 GiB already allocated; 17.75 MiB free; 9.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m proba_dict \u001b[39m=\u001b[39m t5_condProbas\u001b[39m.\u001b[39;49mget_proba_dict(protid_seq_dict_list[\u001b[39m0\u001b[39;49m], mutation_gen)\n\u001b[1;32m      2\u001b[0m \u001b[39m# dmiss_data = t5_condProbas.get_log_odds(proba_dict)\u001b[39;00m\n",
      "File \u001b[0;32m/projects/ashehu/akabir4/venvs/VESPA/vespa/predict/logodds.py:102\u001b[0m, in \u001b[0;36mT5_condProbas.get_proba_dict\u001b[0;34m(self, seq_dict, mutation_gen)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_proba_dict\u001b[39m(\u001b[39mself\u001b[39m, seq_dict, mutation_gen: utils\u001b[39m.\u001b[39mMutationGenerator):\n\u001b[1;32m     98\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m    Compute for all residues in a protein the conditional probabilities for reconstructing single, masked tokens.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprott5\u001b[39m.\u001b[39;49mget_model(LOGODDS)\n\u001b[1;32m    104\u001b[0m     result_dict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    106\u001b[0m     \u001b[39mfor\u001b[39;00m identifier, position_list \u001b[39min\u001b[39;00m tqdm(\n\u001b[1;32m    107\u001b[0m         mutation_gen\u001b[39m.\u001b[39mgenerate_mutation_mask(include_x_pos\u001b[39m=\u001b[39mREPLACE_RARE_AA),\n\u001b[1;32m    108\u001b[0m         desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExtract Sequence Logodds\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    109\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m VERBOSE,\n\u001b[1;32m    110\u001b[0m     ):\n",
      "File \u001b[0;32m/projects/ashehu/akabir4/venvs/VESPA/vespa/predict/utils_t5.py:31\u001b[0m, in \u001b[0;36mProtT5.get_model\u001b[0;34m(self, model_usage)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe intended use of ProtT5 is not implemented.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval()\n\u001b[0;32m---> 31\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mto(DEVICE)\n\u001b[1;32m     32\u001b[0m \u001b[39mreturn\u001b[39;00m model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_tokenizer()\n",
      "File \u001b[0;32m/projects/ashehu/akabir4/venvs/hopper_vespa_marquet_from_source/lib/python3.8/site-packages/transformers/modeling_utils.py:1896\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1891\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1892\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`.to` is not supported for `8-bit` models. Please use the model as it is, since the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1893\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1894\u001b[0m     )\n\u001b[1;32m   1895\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1896\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/projects/ashehu/akabir4/venvs/hopper_vespa_marquet_from_source/lib/python3.8/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m/projects/ashehu/akabir4/venvs/hopper_vespa_marquet_from_source/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/projects/ashehu/akabir4/venvs/hopper_vespa_marquet_from_source/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 641 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m/projects/ashehu/akabir4/venvs/hopper_vespa_marquet_from_source/lib/python3.8/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/projects/ashehu/akabir4/venvs/hopper_vespa_marquet_from_source/lib/python3.8/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/projects/ashehu/akabir4/venvs/hopper_vespa_marquet_from_source/lib/python3.8/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.76 GiB total capacity; 9.02 GiB already allocated; 17.75 MiB free; 9.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "a_prot_seq = protid_seq_dict_list[0]\n",
    "csv_dir = home_dir+\"models/vespa_marquet/outputs/vespa/lm_outputs\"\n",
    "mutation_gen = vespa_utils.MutationGenerator(sequence_dict=a_prot_seq)\n",
    "proba_dict = t5_condProbas.get_proba_dict(a_prot_seq, mutation_gen)\n",
    "dmiss_data = t5_condProbas.get_log_odds(proba_dict)\n",
    "T5_condProbas.write_csv_dir(dmiss_data, csv_dir, mutation_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CXDA'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "seq = \"CUDA\"\n",
    "re.sub(r\"[UZOB]\", \"X\", seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vespa.predict.utils as vespa_utils\n",
    "from pathlib import Path\n",
    "seq_dict = vespa_utils.parse_fasta_input(Path(home_dir+\"models/aa_common/datasets_pmd_analysis/pmd_sequences.fasta\"))\n",
    "print(len(seq_dict))\n",
    "# protid_seq_dict_list = [{prot_id: seq} for prot_id, seq in  seq_dict.items()]\n",
    "protid_seq_dict_list = [(prot_id, seq) for prot_id, seq in  seq_dict.items()]\n",
    "protid, seq = protid_seq_dict_list[0]\n",
    "print(protid, seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hopper_vespa_marquet_from_source",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
