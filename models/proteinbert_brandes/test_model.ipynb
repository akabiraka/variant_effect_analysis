{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "home_dir = \"../../\"\n",
    "module_path = os.path.abspath(os.path.join(home_dir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteinbert import load_pretrained_model, tokenize_seqs\n",
    "from proteinbert.tokenization import token_to_index, index_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_generator, input_encoder = load_pretrained_model(local_model_dump_dir=home_dir+\"models/proteinbert_brandes/cache/\", local_model_dump_file_name=\"epoch_92400_sample_23500000.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[23,  0, 22, ..., 25, 25, 25]], dtype=int32),\n",
       " array([[0, 0, 0, ..., 0, 0, 0]], dtype=int8)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = input_encoder.encode_X([\"ABD\"], 1024) # '<START>'=23, '<END>'=24, <PAD>=25\n",
    "# tokenize_seqs([\"ACD\", \"BCD\"], 3)\n",
    "print(x[0].shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "23\n",
      "24\n",
      "25\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(token_to_index[\"A\"])\n",
    "print(token_to_index[\"<START>\"])\n",
    "print(token_to_index[\"<END>\"])\n",
    "print(token_to_index[\"<PAD>\"])\n",
    "print(token_to_index[\"<OTHER>\"]) # non-standard amino acids are mapped tho <OTHER> token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 26)\n",
      "0 12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96527505"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pretrained_model_generator.create_model(1024)\n",
    "logits, annotations = model(x) # shape=(n_seq=1, seq-len=1024, vocab_size=26), shape=(1, 8943)\n",
    "logits = logits[0].numpy()\n",
    "print(logits.shape)\n",
    "mut_pos = 1\n",
    "wt_tok_idx = token_to_index[\"A\"]\n",
    "mt_tok_idx = token_to_index[\"P\"]\n",
    "print(wt_tok_idx, mt_tok_idx)\n",
    "logits[mut_pos][wt_tok_idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hopper_proteinbert_tf_brandes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
